```
Vol.:(0123456789)
```
```
The Journal of Supercomputing (2021) 77:11597‚Äì
https://doi.org/10.1007/s11227-021-03742-
```
```
A novel cloud workflow scheduling algorithm based
on¬†stable matching game theory
```
```
Zhao‚Äëhong¬†Jia1,2¬†¬∑ Lei¬†Pan1,2¬†¬∑ Xiao¬†Liu^3 ¬†¬∑ Xue‚Äëjun¬†Li^2
```
```
Accepted: 13 March 2021 / Published online: 27 March 2021
¬© The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature
2021
```
```
Abstract
Workflow scheduling is one of the most popular and challenging problems in cloud
computing. However, among the studies on cloud workflow scheduling, very few
consider the fairness among workflow tasks which could significantly delay the
workflows and hence deteriorates user satisfaction. In this paper, we propose a
workflow scheduling algorithm based on stable matching game theory to minimize
workflow makespan and ensure the fairness among the tasks. The local optimiza-
tion methods based on critical path and task duplication are developed to improve
the performance of the algorithm. In addition, a novel evaluation metric is proposed
to measure the fairness among workflow tasks. Comprehensive experiments are
conducted to compare the performance of the proposed algorithm with other four
representative algorithms. Experimental results demonstrate that our algorithm out-
performs the other compared algorithms in terms of all three performance metrics
under different workflow applications.
```
```
Keywords Cloud computing¬†¬∑ Workflow scheduling¬†¬∑ Game theory¬†¬∑ Makespan¬†¬∑
Fairness
```
```
Zhao-hong Jia and Lei Pan have contributed equally to this work.
```
* Xiao Liu
xiao.liu@deakin.edu.au
Zhao-hong Jia
zhjia@mail.ustc.edu.cn
Lei Pan
panlei_ahu@foxmail.com
Xue-jun Li
xjli@ahu.edu.cn

(^1) Key Lab of¬†Intelligent Computing and¬†Signal Processing of¬†Ministry of¬†Education, Hefei, China
(^2) School of¬†Computer Science and¬†Technology, Anhui University, Hefei¬†230039, China
(^3) School of¬†Information Technology, Deakin University, Geelong, Australia


11598 Z.¬†Jia et al.

**1 Introduction**

Cloud computing [1] is a service that efficiently provides a large number of com-
puting resources and automated resource management through software. Users
can access unlimited resources through the network on a pay-as-you-go fashion
[2] without being restricted by time and space. Moreover, cloud resources have
many outstanding characteristics such as elasticity, on-demand provisioning and
virtualization. Furthermore, there are three major types of cloud services, viz.
Infrastructure as a Service (IaaS), Platform as a Service (PaaS) and Software as
a Service (SaaS) [3]. Workflows can represent real-world complex applications
such as in the areas of physics, bio-informatics, weather forecasting and astron-
omy [4, 5]. Most of the workflow scheduling problems in clouds aims at makes-
pan minimization which is known to be NP-complete in the cloud environment
[6]. Proper scheduling can effectively reduce energy consumption of the cloud
data center, increase resource utilization, reduce workflow makespan and improve
user satisfaction. Therefore, how to schedule workflows efficiently on cloud work-
flow scheduling is of great significance.
The scheduling algorithms can be generally divided into heuristic and meta-
heuristic. The former is able to provide approximate solutions with polynomial
time complexity. However, the latter, based on iterative search, can improve solu-
tion quality with more computation time. Heuristic algorithms can be further
divided into list, duplication and clustering scheduling. Meta-heuristic algorithms
mainly include genetic algorithm (GA), particle swarm optimization algorithm
(PSO), memetic algorithm (MA) and so on.
However, most cloud workflow scheduling algorithms focus on the common
objectives such as minimizing the total cost or makespan of the whole workflow.
In reality, there are many workflows such as video surveillance, object tracking
[7] and face recognition [8] where specific tasks in the workflow have their own
objectives such as minimum response time or maximum processing speed. Given
a specific scheduling algorithm, if the current best resources (e.g., with the maxi-
mum bandwidth and maximum processing speed) are always assigned to the tasks
according to their priorities, some tasks may fail to meet the customers‚Äô require-
ments, which is unfair. Therefore, unfair allocation of resources will lead to a
significant decrease on the satisfaction of some task objectives, which in turn will
affect customer satisfaction in the cloud services. Therefore, the fairness among
the workflow tasks needs to be considered along with the global workflow objec-
tives [9‚Äì11]. However, there are few studies on task fairness in workflow schedul-
ing. Inspired by the widely adoption of stable matching game theory (SMGT) in
balancing fairness and competition among tasks, this paper proposes a workflow
scheduling algorithm in heterogeneous cloud environments based on SMGT [12,
13] to minimize workflow makespan and ensure the fairness among the tasks. To
the best of our knowledge, this is the first attempt of SMGT on workflow sched-
uling problems and has achieved relatively good results. Specifically, in order to
improve the efficiency, two local optimization methods based on critical path [14]
and task duplication [15‚Äì17] are incorporated into the algorithm. The target of


11599
A novel cloud workflow scheduling algorithm based on¬†stable...

our algorithm is to distribute multiple cloud workflows with different sizes to vir-
tual machines (VMs) with different processing capacities in the cloud to minimize
the workflow makespan and maximize the fairness among the workflow tasks.
The major contributions of this paper are as follows:

- The fairness of workflow tasks is considered and a novel scheduling algorithm
    based on SMGT is proposed to balance between the global objectives of the
    workflows and the fairness of the workflow tasks.
- Local optimization methods based on critical path and task duplication are
    designed to improve the efficiency of the algorithm.
- A novel evaluation metric is proposed to measure the fairness among workflow
    tasks.
- The proposed algorithm is compared with other four representative algorithms
    through comprehensive experiments on four typical workflow structures.

The remainder of the paper is organized as follows. Section¬†2 reviews the work-
flow scheduling of Cloud in recent years. Section¬†3 defines the workflow model, the
cloud model and the problem formulation. Section¬†4 describes the proposed algo-
rithm, as well as an example, in detail. The experimental results and the analysis on
the results are provided in Sect.¬†5. Section¬†6 concludes the paper.

**2 Literature review**

In recent years, a lot of studies on workflow scheduling in the cloud have been pro-
posed. Generally speaking, cloud workflow scheduling algorithms can be divided
into two categories including heuristics and meta-heuristics (see Table¬†1). Hetero-
geneous earliest finish time (HEFT) [14] is one of the most popular heuristic algo-
rithms. It minimized the completion time of the workflow by assigning an upward
rank value to all tasks and insertion approach. In addition, another method of pri-
oritizing tasks with the sum of upward and downward rank values was proposed to
calculate the rank value of tasks called Critical-Path-on-a-Processor (CPOP). At the
stage of processor selection, priority is incorporated to schedule the critical tasks.
Experimental results have verified the superiority of the two methods in solution
quality and search speed. Based on HEFT, many improved algorithms have been
proposed. Samadi et¬†al. [18] presented an enhancement heterogeneous earliest finish

**Table 1** Classification of workflow scheduling algorithms

```
Objective
Makespan Cost Energy Flowtime Fairness
```
Heuristics [14, 18‚Äì29] [20, 21, 24] [22]
Meta-heuristics [31‚Äì34, 36] [31‚Äì36] [35] [31, 32]
Game theory [39, 40] [38‚Äì40] [37] [39]


11600 Z.¬†Jia et al.

time algorithm (E-HEFT) taking into account the users‚Äô financial constraints and
load balancing between VMs to minimize the makespan of workflow. Cao et¬†al. [19]
presented the Top-k strategy, called K-HEFT, where, in each assignment, the _k_ most
schedulable tasks are selected, according to their priority, to be allocated, in order to
reduce the minimum completion time of the workflow.
Considering the constraint of deadline, the variability of performance of VMs
and the delay of instance acquisition, Sahni et¬† al. [20] proposed a heuristic algo-
rithm to minimize the cost and makespan. Zheng et¬†al. [21] proposed three different
algorithms. The first algorithm, called CFMax (Change From Maximum), generates
schedule using algorithm HEFT and then redistributes tasks based on cost reduc-
tion. The second, called CRR (cost‚Äìruntime ratio), considers makespan reduction
based on the result of CFMax. The third, CBT-MD (Compete between tasks by
Manhattan distance) and CBT-ED (compete between tasks by Euclidean distance)
conduct global evaluation through two different measurements on pre-schedule. All
of these algorithms can reduce the execution cost of workflow without violating the
constraint of deadline. Moreover, CBT-MD and CBT-ED perform best among these
algorithms, meaning that the reassigned schedule by the global evaluation helps to
achieve better results. Wu et¬† al. [22] proposed a soft error-aware task scheduling
approach for workflows in dynamic voltage and frequency scaling cloud data cent-
ers. The approach can generate energy-efficient task schedules for workflows under
the constraints of reliability and completion time. Ijaz and Munir [23] proposed a
list scheduling heuristic with optimized duplication to reduce the makespan of work-
flow. The proposed algorithm improves the performance measurements and ensures
the same time complexity as those of the existing algorithms. Zhang et¬†al. [24] first
described the workflow scheduling problem as an integer programming problem.
They proposed a job-prioritization scheme that maintains the priorities of tasks with
precedence constraints and assigns priorities to tasks without precedence constraints
based on their importance. They finally designed a uniform spare budget-splitting
strategy that splits the spare budget uniformly, resulting in better extra demand on
average and improvement on makespan of workflow. Djigal et¬†al. [25] proposed an
improved predict priority task scheduling algorithm with two phases: task prioriti-
zation and processor selection. The algorithm reduced the makespan of workflow
significantly by looking ahead in two phases. Geng et¬†al. [26] proposed a new algo-
rithm based on task duplication and task grouping to minimize the total execution
time of workflow. Kumar et¬†al. [27] proposed a novel algorithm based on the granu-
larity of tasks in a workflow to minimize the makespan and maximize the average
VM utilization. Gupta et¬† al. [28] calculate the dynamic threshold of tasks through
min‚Äìmax normalization to ensure the makespan and the cloud resource utilization
of each workflow. Min‚Äìmin [29] is one of the common benchmark workflow sched-
uling algorithms that can intuitively reflect the performance of different algorithms.
At present, most heuristic algorithms are focusing on optimizing one sin-
gle objective with certain constraints, which is ideal [30]. To solve the multi-
objective problems of workflow scheduling, which are closer to reality, meta-
heuristic algorithms have exhibited their superiorities. Taking the costs of both
data transmission and computation into consideration, Wu et¬† al. [31] proposed
a revised discrete PSO to schedule the workflows. In order to minimize three


11601
A novel cloud workflow scheduling algorithm based on¬†stable...

objectives, i.e., flowtime, makespan and resource usage cost, Kaur and Kadam
[32] extended the original bacteria foraging algorithm and a new fitness assign-
ment method and bacteria selection strategy are incorporated to optimize mul-
tiple objectives, simultaneously. However, their method considers independent
tasks, which is unsuitable for workflow scheduling problems. Therefore, on the
basis of PSO, Hu et¬†al. [33] proposed a multi-objective scheduling algorithm to
minimize makespan and cost of workflow, simultaneously, with considering the
constraint of reliability. Moreover, in the encoding method, both the execution
location of tasks and the order of tasks for data transmission are taken into con-
sideration. Huang et¬†al. [34] added a heuristic algorithm called simplified swarm
optimization to PSO, where dynamic parameters are designed to adjust local
and global search abilities of the algorithm. Ding et¬† al. [35] presented a cost-
effective scheduling strategy based on PSO for multi-workflow under the con-
straints of deadline in Fog computing. Alsmady et¬†al. [36] proposed a Memetic
algorithm where hill climbing local search is adopted as an extra operator for
Genetic Algorithm to improve solutions during global search. The experimental
results showed that the MA is able to decrease the makespan and cost of the
workflow at the same time.
Compared with heuristics, meta-heuristic algorithms have advantageous in
finding better solutions to workflow scheduling problems. However, the compu-
tation time of meta-heuristic algorithms is much higher than that of heuristics
in general. As a result, when response time is needed or problem scale is larger,
the meta-heuristic algorithms are not suitable enough. Therefore, the heuristic
algorithms are preferable for addressing the studied problem with one single
objective. Game theory (GT) mainly focuses on the strategic interaction among
rational decision-makers and is widely applied in all fields of logic, systems sci-
ence and so on. Considering the reliability of balanced tasks, Yang et¬† al. [37]
presented a task scheduling algorithm based on the cooperative game model so
that the complexity of the proposed algorithm is reduced, as well as the effi-
ciency being ensured. To solve the task scheduling in computational grid, Gao
et¬†al. [38] treated the grid load-balancing problem as non-cooperative game and
proposed a GT-based algorithm to minimize the cost of the grid. The experiment
results demonstrate that the game-based algorithm has a desirable capability to
resolve the task scheduling problem. Wang et¬†al. [39] proposed a multi-objective
workflow scheduling algorithm based on dynamic game-theoretic model to min-
imize makespan and total cost and maximize system fairness in terms of work-
load distribution among heterogeneous cloud VMs. Sujana et¬†al. [40] formulated
the multi-objective scheduling of workflows as a new sequential cooperative
game with two objectives of minimizing the execution time and the economic
cost on two constraints.
Although GT has shown advantages in workflow scheduling, there are still
very few studies considering the issue of task fairness. Hence, in this paper, we
apply the stable matching algorithm, one of the models in GT, to solve cloud
workflow scheduling with the aim to simultaneously minimize the makespan of
workflow and maximize the fairness of workflow tasks.


11602 Z.¬†Jia et al.

**3 Problem description**

To describe the studied problem clearly, the workflow model, the cloud model and
the problem formulation are provided in this section. The major notations are firstly
given in Table¬†2.

**3.1 Workflow model**

A workflow model is usually represented by a directed acyclic graph (DAG)
[41‚Äì44]. An example of the studied workflow model is illustrated as Fig.¬†1. In Fig.¬†1,
_DAG_ =( _T_ , _E_ ) , where _T_ ={ _t_ 0 , _t_ 1 ,..., _tn_ ‚àí 1 } denotes a set of _n_ tasks and _E_ represents
the dependencies between tasks. The predecessors set and the successors set of _ti_
are denoted by _pre_ ( _ti_ ) and _succ_ ( _ti_ ) , respectively. Each task with no predecessor is
known as entry task _tentry_ , and each task with no successor is known as exit task _texit_.
It is notable that there may be more than one entry task or more than one exit task
in a DAG model. If all predecessors of one task are completed and the data from

**Table 2** List of notations Notation Definition

```
level Level of workflow
n Number of tasks
id Index of task
ti Task ti of workflow
si Size of ti
TTi , j Size of data transmission from ti to tj
preference ( ti ) Preference array of task ti
pre ( ti ) Predecessor set of ti
succ ( ti ) Successor set of ti
Ttrans ( ti , tj ) Transmission time from ti to tj
AST ( ti ) Actual start time of ti
AFT ( ti ) Actual finish time of ti
ET ( ti , VMk ) Execution time of ti on VMk
FT ( ti , VMk ) Finish time of ti on VMk
CP The set of tasks on critical path
m Number of VMs
pk Processing capacity of VMk
threshold ( VMk , l ) Number of tasks allowed to be
performed on VMk in level l
preference ( VMk ) Preference array of VMk
waiting ( VMk ) Waiting array of VMk
avail ( VMk ) Available time of VMk
B ( VMk , VMl ) Bandwidth between VMk and VMl
makespan Makespan of workflow
utilization Utilization of VM
```

```
11603
A novel cloud workflow scheduling algorithm based on¬†stable...
```
```
predecessors arrive, the task can be started to execute. The size of data transmission
between tasks can be represented by a matrix denoted by TT as follows:
```
```
where TTi , j = 0 if there are no constraint relationships between ti and tj or i = j. The
element TTi , j , ( 0 ‚â§ i ‚â§ n ‚àí 1 , 0 ‚â§ j ‚â§ n ‚àí 1 ) represents the size of data transmission
from ti to tj.
```
```
3.2 Cloud model
```
Assume the infrastructure to be a service (IaaS) cloud system that consists of a set
of _m_ VMs [45], denoted by _V_ ={ _VM_ 0 , _VM_ 1 ,..., _VMm_ ‚àí 1 }. All the VMs are inde-
pendent of each other and have different processing capabilities. Let _B_ denote a
matrix representing the bandwidth between different VMs. Note that this matrix is
unnecessarily symmetric. That is, _B_ ( _VMk_ , _VMl_ ) may not be equal to _B_ ( _VMl_ , _VMk_ ).
Moreover, it is obvious that _B_ ( _VMk_ , _VMl_ )= 0 , if _k_ = _l_. The transmission time,
denoted by _Ttrans_ ( _ti_ , _tj_ ) , from _ti_ executed on _VMk_ to _tj_ on _VMl_ , is determined by the
size of data transmission _TTi_ , _j_ from _ti_ to _tj_ and bandwidth between _VMk_ and _VMl_.
Note that _Ttrans_ ( _ti_ , _tj_ )= 0 , if the two tasks are executed on the same VM. Specifically,
_Ttrans_ ( _ti_ , _tj_ ) is calculated by Eq. (2).

```
TTi , j = (1)
```
### ‚é°

### ‚é¢

### ‚é¢

### ‚é¢

### ‚é£

```
0 TT 0,1 ‚ãØ TT 0, n ‚àí 1
TT 1,0 0 ‚ãØ TT 1, n ‚àí 1
‚ãÆ‚ãÆ‚ãÆ‚ãÆ
TTn ‚àí1,0‚ãØ‚ãØ 0
```
### ‚é§

### ‚é•

### ‚é•

### ‚é•

### ‚é¶

```
Fig. 1 An example of CyberShake workflow with 30 tasks
```

11604 Z.¬†Jia et al.

The start time of _ti_ on _VMk_ , denoted by _ST_ ( _ti_ , _VMk_ ) , is calculated as Eq. (3).

The execution time of _ti_ on _VMk_ , denoted by _ET_ ( _ti_ , _VMk_ ) , is defined as the ratio
between the size of the task and the processing capacity of _VMk_ and shown as Eq.
(4).

The finish time of _ti_ on _VMk_ , denoted by _FT_ ( _ti_ , _VMk_ ) , formulated by Eq.¬†(5).

**3.3 Problem formulation**

The makespan of workflow, which is used to evaluate the performance of the pro-
posed algorithm, equals to the maximum completion time of all tasks in the work-
flow [46‚Äì49]. Let _MS_ ( _VMk_ ) denote the makespan of _VMk_ , 0 ‚â§ _k_ ‚â§ _m_ ‚àí 1 , then the
makespan of workflow is defined as Eq. (6):

In addition, the following metrics, based on makespan, to measure the performance
of algorithms more intuitively and be formulated as follows.

(1) Scheduling length ratio ( _SLR_ ) [ 50, 51]. In order to avoid large differences in
makespan caused by different parameters, it is necessary to normalize the makes-
pan to a lower bound. This metric is the ratio of the makespan of workflow to the
sum of the minimum computation time of those tasks in _CP_. _SLR_ is calculated
as Eq. (7).

(2) Average VM utilization ( _AVU_ ) [52, 53]. It is defined as the ratio of execution
time of all tasks on one VM to the makespan of workflow. The utilization rate
of _VMk_ is formulated as Eq. (8):

```
Ttrans ( ti , tj )= (2)
```
```
TTi , j
B ( VMk , VMl )
```
```
ST ( ti , VMk )= (3)
```
### 

```
0 t = tentry
max
tj ‚àà pre ( ti )
```
```
{ FTj + Ttrans ( ti , tj )} t ‚â† tentry.
```
```
ET ( ti , VMk )= (4)
```
```
si
pk
```
### .

```
FT ( ti , VMk )= ST ( ti , VMk )+ ET ( ti , VMk ). (5)
```
```
makespan =max( MS ( VMk )),0‚â§ k ‚â§ m ‚àí 1. (6)
```
### SLR = (7)

```
makespan
‚àëÔøΩ CP ÔøΩ‚àí 1
i = 0 ( min
```
```
‚àë m ‚àí 1
k = 0 ET ( ti , VMk ))
```
### .

```
VU ( VMk )= (8)
```
### ‚àë

```
ET ( ti , VMk )
makespan
```
```
, i ‚àà VMk. waiting.
```

11605
A novel cloud workflow scheduling algorithm based on¬†stable...

```
And the average utilization of all VMs is defined as Eq. (9):
```
(3) Variance of fairness ( _VF_ ). This is a new metric designed to measure the fairness
between tasks. It is defined based on the satisfaction of each task. The ratio of
the actual execution time _AET_ and the expected execution time _EET_ of each task
is calculated as the satisfaction of each task _S_. It is formulated as Eq. (10).

```
where EET is the execution time of the task on the fastest VM. Obviously, the
higher the value of S , the better the task satisfaction. The degree of deviation
of all task satisfaction from their average is used to measure the fairness of all
tasks. The variance of fairness is formulated is as follows:
```
```
where M is the average of all task satisfaction. Apparently, the smaller its
value, the fairer the algorithm is for all tasks.
```
**4 Proposed algorithm**

The proposed algorithm, named SM-CPTD, is based on SMGT. SM-CPTD is
designed to effectively coordinate individual and population goals while balancing
VMs load and resource utilization. In addition, methods for selection and generating
the preference list are presented. To improve solution quality, two local optimization
methods, based on critical path and task duplication, are also incorporated into the
algorithm. There are three main stages in the proposed algorithm and are shown in
Algorithm¬† 1. Firstly, determining the critical path (DCP) is designed to determine
the critical path of the DAG. Secondly, the SMGT is applied to generate the pre-
schedule scheme. Finally, the pre-schedule scheme is improved by the local optimi-
zation strategy based on task duplication (LOTD).

### AVU = (9)

### 1

```
m
```
```
m ‚àí 1
```
```
k = 0
```
```
VU ( VMk ).
```
```
Si = (10)
```
```
AETi
EETi
```
### VF = (11)

### 1

```
n
```
```
 n ‚àí^1
```
```
i = 0
```
```
( M ‚àí Si )^2
```

11606 Z.¬†Jia et al.

**4.1 Local optimization based on¬†critical path**

The method in HEFT [14] is utilized to calculate the critical path of a DAG. In this
method, based on the average computation and communication time, each task is
assigned a rank during the process of traversing the entire DAG from the exit tasks
to the entry tasks. The rank of _ti_ , representing the length of the longest path from _ti_
to the exit task, is recursively defined as Eq. (12):

where _Wi_ denotes the average computation time for _ti_ , and _ci_ , _j_ denotes the average
communication time of _edge_ ( _ti_ , _tj_ ). For the exit tasks, _rank_ ( _texit_ )= _Wexit_. Each task
with the largest rank in the same level is selected to construct the critical path. Then,
the tasks in the critical path are scheduled on the VM that can obtain the earliest
completion time because reducing the total execution time of the jobs in the critical
path can effectively decrease the makespan of a DAG [14, 15].
DCP is described as follows.

**4.2 Stable matching game theory**

SMGT is one of the latest theories of modern economics, which can achieve a high
degree of integration of fairness and efficiency in allocation public resources. More-
over, it has been successfully applied to solve different types of problems, such as
the matrimonial problem, students‚Äô school choice problem and so on. Furthermore,
SMGT has shown significant advantages in helping participants generate a strict
preference order at a lower cost.
A stable matching model in workflow scheduling problem consists of two sets
of participants, i.e., the set _T_ of tasks and the set _V_ of VMs, where all individuals in
_T_ have a preference matrix for all individuals in _V_ , and all individuals in _V_ have a
preference matrix for all individuals in _T_. The preference matrix of a task is gener-
ated based on the ascending order of its finish time on different VMs. Similarly, the
preference matrix of a VM for tasks is generated according to the ascending order
of their finish time on this VM. The goal is to find a stable match that allows each
individual to get the most desired object as possible.

```
rank ( ti )= Wi + tj ‚ààmax succ ( ti )( ci , j + rank ( tj )) (12)
```

11607
A novel cloud workflow scheduling algorithm based on¬†stable...

Because of the particularity of workflow scheduling problem, the hierarchical
matching method is employed in this paper. First, the tasks in level _l_ are assigned
to the most preferred VM according to their preference matrix. In addition, to avoid
lots of tasks being assigned to the fastest VM, it is necessary to set the threshold of
VMs. That is, task is allowed to be assigned to _VMk_ if _threshold_ ( _k_ , _l_ ) _>_ 0 ; otherwise,
the task with the largest preference value in the waiting list of _VMk_ is eliminated and
reassigned. The reassigned task selects another VM according to task‚Äôs preference
matrix. Repeat the above steps until all tasks in level _l_ are assigned. _threshold_ ( _k_ ,¬† _l_ ) is
calculated based on the number of tasks in each level in the DAG and the process-
ing capacity of each VM so that the more powerful VM can handle more tasks. As a
result, the high-speed VM will handle more tasks than the low-speed machine. The
threshold of _VMk_ in level _l_ is given by Eq. (13).

where _nl_ denotes the number of tasks in level _l_.
Since the order of task assignment has little effect on the result of SMGT, the
priority of tasks is ignored in the proposed algorithm. Moreover, once a task _ti_ is
assigned, _ACT_ ( _ti_ ) and _AFT_ ( _ti_ ) are updated, and preference values for the other tasks
are assigned. The SMGT is described as follows.

```
threshold ( k , l )= (13)
```
```
‚àë l ‚àí 1
v = 0 nv
‚àë m ‚àí 1
i = 0 pi
```
```
√ó pk
```

11608 Z.¬†Jia et al.

**4.3 Local optimization based on¬†task duplication**

The essence of task duplication is to use idle time of VMs to reduce the makespan.
That is, the redundant tasks are utilized to reduce the communication time between
tasks. Furthermore, in order to avoid excessive waste of space, only consider dupli-
cating tasks in the first level in DAG. Specifically, task _ti_ can be duplicated and
assigned to another VM if both the following two rules are satisfied: (1) _ti_ can only
be duplicated and placed to the VMs where its successors are assigned to. (2) The
completion time of the other tasks in the waiting list of the selected VM cannot
increase after the duplication of _ti_ is assigned to this VM.
LOTD is described as Algorithm¬†4.


```
11609
A novel cloud workflow scheduling algorithm based on¬†stable...
```
```
4.4 Case study
```
To illustrate the above process more clearly, an example with CyberShake work-
flow is provided as shown in Fig.¬†1. In Fig.¬†1, there are 30 tasks, denoted by
_T_ ={ _t_ 0 , _t_ 1 , _t_ 2 ,..., _t_ 29 } , with four levels and 52 edges between the tasks. The sizes
of tasks are shown in Table¬†3, where the rank of each task is calculated according
to Eq. (8).¬†The rank in bold in Table¬†3 is represented the task with the largest rank
per level.¬†The matrix _TT_ representing the size of data transmission between tasks
is calculated as: _TTi_ , _j_ = _sti_ √ó _CCR_ , where _CCR_ =0.4 , and _CCR_ denotes the ratio of

```
Table 3 Sizes and ranks of tasks
t 0 t 1 t 2 t 3 t 4 t 5 t 6 t 7 t 8 t 9
```
```
Size 50 40 46 37 37 39 44 40 44 31
Rank 7.14 5.71 44.69 22.23 14.67 35.34 27.41 24.23 16.09 19.
t 10 t 11 t 12 t 13 t 14 t 15 t 16 t 17 t 18 t 19
```
```
Size 30 43 33 42 46 45 46 46 41 49
Rank 13.24 22.6 13.85 34.61 25.66 16.3 25.86 16.5 25.45 17.
t 20 t 21 t 22 t 23 t 24 t 25 t 26 t 27 t 28 t 29
Size 40 39 47 46 37 43 42 38 39 42
Rank 23.21 15.08 26.06 16.5 23.42 15.89 23.42 14.87 23.62 15.
```

11610 Z.¬†Jia et al.

the average communication cost to the average computation cost. The processing
capacity of the five VMs is 5, 8, 7, 9 and 6, respectively. The bandwidths between
VMs are shown in Table¬†4.
According to Table¬†3, the critical path is { _t_ 2 , _t_ 5 , _t_ 6 , _t_ 0 }. Two cases, that is,
level-0 and level-1, are provided and shown in Tables¬†5 and 6. The task that need
to be reassigned is shown in bold in Table¬†6.¬†Since there is no data transmission
from predecessors to the tasks in level-0, only in the case of finish time of tasks,
the array of preference for all VMs is the same.
The Gantt chart of the solution obtained by the proposed algorithm SM-CPTD
is shown as Table¬†7. In Table¬†7, symbols ‚Äò ‚àó ‚Äô and ‚Äò ‚àº ‚Äô represent the idle time slot
of VM and the duration of the assigned task in the solution, respectively. Moreo-
ver, duplicated tasks are shown in boldface.

**4.5 Complexity analysis**

Here, we present the complexity analysis for SM-CPTD. There are three main
procedures in SM-CPTD, namely determining critical path, stable matching game
theory and task duplication. Let _n_ , _l_ and _m_ denote the number of total tasks, the
total number of levels in the workflow and the number of active VMs, respec-
tively. In Algorithm¬†2, the time complexity of calculating the rank value for each
task and determining the critical path is _O_ ( _n_^2 ). In Algorithm¬†3, the loop from Step
2 to Step 35 repeats _l_ times. Step 3 requires _O_ ( _n_ ). In the ideal case, that is, each
task is assigned to the best VM, the loop from Step 9 to Step 34 requires _O_ ( _nm_ ).
However, in the worst case, each matched task is always rejected later, causing _n_
matches to succeed totally, whose time complexity requires _O_ ( _n_^2 ). It is obvious
that the time complexity of Algorithm¬† 4 is _O_ ( _nm_ ). Therefore, the overall time
complexity of SM-CPTD is _O_ ( _n_^2 _l_ ).

**5 Simulation and¬†analysis**

In this section, comprehensive experiments are conducted to measure the perfor-
mance of SM-CPTD with the other four algorithms and to verify the effectiveness
of the proposed strategies.

**Table 4** Bandwidth between
VMs _VM_^1 _VM_^2 _VM_^3 _VM_^4 _VM_^5

```
VM 1 0 7 8 9 6
VM 2 5 0 8 7 5
VM 3 7 6 0 8 4
VM 4 7 8 6 0 5
VM 5 9 7 6 4 0
```

11611
A novel cloud workflow scheduling algorithm based on¬†stable...

```
Table 5
```
```
Results of level-
```
```
VM.preference
```
```
VM.threshold
```
```
VM
```
```
1
```
```
2,¬†
```
```
1
```
```
VM
```
```
2
```
```
2,¬†
```
```
1
```
```
VM
```
```
3
```
```
2,¬†
```
```
1
```
```
VM
```
```
4
```
```
2,¬†
```
```
1
```
```
VM
```
```
5
```
```
2,¬†
```
```
1
```
```
Unassigned task
```
```
Task
```
```
Task.preference
```
```
VM
```
```
VM.waiting
```
```
Task.AST
```
```
Task.AFT
```
```
2, 13
```
```
2
```
```
3
```
```
2
```
```
0
```
```
5.
```
```
13
```
```
13
```
```
2, 3, 5, 1, 4
```
```
2
```
```
13
```
```
0
```
```
5.
```

11612 Z.¬†Jia et al.

```
Table 6
```
```
Results of level-
```
```
VM.preference
```
```
VM.threshold
```
```
VM
```
```
1
```
```
22, 16, 14, 26, 18, 20,
11, 24, 7, 5, 3, 9, 28
```
```
3
```
```
VM
```
```
2
```
```
11, 7, 5, 3, 9, 22,
14, 16, 26, 18, 20, 24, 28
```
```
4
```
```
VM
```
```
3
```
```
11, 22, 7, 16, 14, 5, 3,
26, 18, 20, 9, 24, 28
```
```
3
```
```
VM
```
```
4
```
```
22, 16, 14, 26, 18, 20,
24, 11, 7, 5, 3, 9, 28
```
```
4
```
```
VM
```
```
5
```
```
22, 16, 14, 11, 26,
7, 18, 5, 20, 3, 24, 9, 28
```
```
3
```
```
Unassigned task
```
```
Task
```
```
Task.preference
```
```
VM
```
```
VM.waiting
```
```
Task.AST
```
```
Task.AFT
```
```
3, 5, 7, 9, 11, 14,
16, 18, 20, 22, 24, 26, 28
```
```
5
```
```
4
```
```
2, 5
```
```
5.
```
```
9.
```
```
3, 7, 9, 11, 14, 16, 18,
20, 22, 24, 26, 28
```
```
3
```
```
2, 4, 3, 1, 5
```
```
2
```
```
13, 3
```
```
7.
```
```
11.
```
```
7, 9, 11, 14, 16, 18,
20, 22, 24, 26, 28
```
```
7
```
```
3, 4, 5, 1, 2
```
```
3
```
```
7
```
```
8.
```
```
13.
```
```
9, 11, 14, 16, 18, 20,
22, 24, 26, 28
```
```
9
```
```
4, 1, 5, 2, 3
```
```
4
```
```
2, 5, 9
```
```
9.
```
```
12.
```
```
11, 14, 16, 18, 20, 22,
24, 26, 28
```
```
11
```
```
5, 1, 2, 4, 3
```
```
5
```
```
11
```
```
8.
```
```
15.
```
```
14, 16, 18, 20, 22, 24,
26, 28
```
```
14
```
```
1, 4, 2, 3, 5
```
```
1
```
```
14
```
```
8.
```
```
17.
```
```
16, 18, 20, 22, 24,
26, 28
```
```
16
```
```
2, 4, 3, 5, 1
```
```
2
```
```
13, 3, 16
```
```
11.
```
```
17.
```

## A novel cloud workflow scheduling algorithm based on¬†stable...

(continued)

Unassigned task

Task

Task.preference

VM

VM.waiting

Task.AST

                        -
- Table
   - 18, 20, 22, 24, 26, Task.AFT
   -
   - 4, 3, 5, 2,
   -
   - 2, 5, 9,
   - 12.
   - 17.
      - 20, 22, 24, 26,
      -
      - 3, 5, 4, 2,
      -
      - 7,
      - 13.
      - 19.
         - 22, 24, 26,
         -
         - 4, 5, 2, 1,
         -
         - 2, 5, 22,
         - 9.
         - 14.
            - 24, 26, 28,
            -
            - 5, 4, 2, 1,
            -
            - 11,
            - 15.
            - 22.
               - 26, 28,
               -
               - 2, 4, 3, 1,
               -
               - 13, 3, 16,
               - 17.
               - 22.
                  - 28,
                  -
                  - 4, 1, 3, 5,
                  -
                  - 14,
                  - 17.
                  - 25.
                     -
                     -
                     - 4, 3, 2, 5,
                     -
                     - 7, 20,
                     - 19.
                     - 23.


11614 Z.¬†Jia et al.

**5.1 Experimental settings**

The proposed algorithm is tested on four benchmark workflows in Fig.¬†2, namely
Montage, CyberShake, LIGO and Epigenomics [54]. The parameters in this arti-
cle and the range of values are shown in Table¬†8, which can be referred to [27].
The sizes of tasks, processing capacities of VMs and bandwidth between VMs
are randomly generated by uniform distribution. The range of _CCR_ indicates
the transition of workflows from computation-intensive to data-intensive with

**Table 7** Gantt chart of SM-CPTD

VM1 0 ‚àº 8.4 8.4 ‚àº 17.6 17.6 ‚àº 25.4 25.4 ‚àº 34.
**ùê≠ùüèùüë** _t_ 14 _t_ 28 _t_ 15
VM2 0 ‚àº 5.25 5.25 ‚àº 7.36 7.36 ‚àº 11.99 11.99 ‚àº 17.74 17.74 ‚àº 22.
**ùê≠ùüèùüë** ‚àó _t_ 3 _t_ 16 _t_ 26
22.99 ‚àº 27.61 27.61 ‚àº 31.74 31.74 ‚àº 37.
_t_ 4 _t_ 12 _t_ 23
VM3 0 ‚àº 6.57 6.57 ‚àº 12.29 12.29 ‚àº 18 18 ‚àº 22.43 22.43 ‚àº 26.
**ùê≠ùüê** _t_ 7 _t_ 20 _t_ 9 _t_ 10
26.71 ‚àº 33.29 33.29 ‚àº 39.
_t_ 17 _t_ 25
VM4 0 ‚àº 5.11 5.11 ‚àº 9.44 9.44 ‚àº 14.67 14.67 ‚àº 19.22 19.22 ‚àº 24.
**ùê≠ùüê** _t_ 5 _t_ 22 _t_ 18 _t_ 6
24.11 ‚àº 27.07 27.07 ‚àº 31.51 31.51 ‚àº 36.96 36.96 ‚àº 41.18 41.18 ‚àº 45.
‚àó _t_ 1 _t_ 19 _t_ 27 ‚àó
45.83 ‚àº 51.
_t_ 0
VM5 0 ‚àº 7.67 7.67 ‚àº 14.83 14.83 ‚àº 21 21 ‚àº 28.33 28.33 ‚àº 34.
**ùê≠ùüê** _t_ 11 _t_ 24 _t_ 8 _t_ 21
34.83 ‚àº 41.
_t_ 29

**Fig. 2** Structures of the workflows in the experiments


11615
A novel cloud workflow scheduling algorithm based on¬†stable...

the increase in _CCR_. Moreover, all algorithms are implemented and executed
under Eclipse R2019 version 4.13.0 on an Intel core i7-9750H CPU @ 2.60GHz,
2.60GHz and 8GB RAM on Microsoft Windows 10 Professional 64-bit operating
system.

**5.2 Experimental results**

The experimental results are discussed from two aspects, that is, measuring the
performance of SM-CPTD and verifying the effectiveness of the proposed strate-
gies. The detailed experimental results are shown in Figs.¬†3, 4, 5, 6, 7, 8, 9, 10,
11 and 12. In order to reduce the impact of experimental uncertainties, each algo-
rithm is run 10 times on each instance to obtain the average results.

**Table 8** Parameters and range
of values Parameter Range of value

```
Workflow type Montage/Cyber-
Shake/LIGO/Epig-
enomics
Scale of workflow small/medium/large
Size of tasks 500 ‚àº 700 (MIP)
Number of VMs 5/10/
Processing capacities of VMs 10 ‚àº 20 (MIPS)
Bandwidth between VMs 20 ‚àº 30 (Mbps)
CCR 0.4 ‚àº 2.
```
**Fig. 3** Comparison of _SLR_ in CCRs and small-scale workflows


```
11616 Z.¬†Jia et al.
```
```
5.2.1 Verification of¬†SM‚ÄëCPTD
```
To comprehensively evaluate the performance of SM-CPTD, TDA [26], GSS
[27], NMMWS [28] and min‚Äìmin [29] are selected as the comparative algorithms.
In addition, the time complexity of TDA, GSS, NMMWS and min‚Äìmin is _O_ ( _n_^3 ) ,
_O_ ( _n_^2 _m_ ) , _O_ ( _n_^3 _ml_ ) and _O_ ( _n_^2 _m_ ) , according to Geng et¬†al. [26], Kumar et¬†al. [27], Gupta

```
Fig. 4 Comparison of SLR in CCRs and medium-scale workflows
```
```
Fig. 5 Comparison of SLR in CCRs and large-scale workflows
```

11617
A novel cloud workflow scheduling algorithm based on¬†stable...

et¬†al. [28] and Maheswaran et¬†al. [29], respectively. Clearly, our proposed SM-CPTD
algorithm (with a time complexity of _O_ ( _n_^2 _l_ ) ) has the similar time complexity as
min‚Äìmin which is generally regarded as one of the most efficient scheduling algo-
rithms for benchmarking purpose.
To investigate how the performance of algorithms impacted by CCR and _m_ , the
numbers of VMs for small, medium and large workflows are set to 5, 10 and 50,

**Fig. 6** Comparison of _AVU_ in CCRs and small-scale workflows

**Fig. 7** Comparison of _AVU_ in CCRs and medium-scale workflows


11618 Z.¬†Jia et al.

respectively, when the influence of CCR on each algorithm is considered. Similarly,
when considering the impact of _m_ , the value of CCR is set to 1. Meanwhile, to study
the _VF_ of different algorithms in different workflows, we set _m_ as 50 and CCR as 1.
The evaluation results are shown in Figs.¬†3, 4, 5, 6, 7, 8, 9, 10 and 11.
It can be apparently observed from Figs.¬†3, 4 and 5 that the values of _SLR_
obtained by all algorithms increment as the values of CCR increase from 0.4 to 2,

**Fig. 8** Comparison of _AVU_ in CCRs and large-scale workflows

**Fig. 9** Comparison of _SLR_ in large-scale workflows and different numbers of VMs


11619
A novel cloud workflow scheduling algorithm based on¬†stable...

**Fig. 10** Comparison of _AVU_ in large-scale workflows and different numbers of VMs

**Fig. 11** Comparison of _VF_ in different large-scale workflows

**Fig. 12** Comparison of _SLR_ , _AVU_ and _VF_ for different methods


11620 Z.¬†Jia et al.

which prolongs the transmission time of data between tasks. As a result, the comple-
tion time of workflows increases. However, SM-CPTD shows the average improve-
ment of 20.93% over TDA, 2.66% over GSS, 5.25% over NMMWS and 11.55% over
min‚Äìmin in terms of _SLR_ , respectively. That is, SM-CPTD obtains the minimum
_SLR_ , corresponding to the minimum makespan, on instances of different scales of
workflows among all compared algorithms. Moreover, the performance of GSS is
comparable with that of NMMWS, and both they and min‚Äìmin beat that of TDA in
most cases.
In TDA, a large number of tasks are replicated to decrease the transmission time
between tasks, which can lead to data redundancy and extra execution time of tasks.
So it performs better in data-intensive workflows than in computation-intensive
workflows. The performance of NMMWS depends on the sizes of tasks and the
computing capability of VMs. Specifically, NMMWS under-performs in the case of
small-sized tasks because NMMWS is hard to obtain fine batching results.
From Figs.¬†6, 7 and 8, it can be seen that the values of _AVU_ of all algorithms
decrease with the increase in CCR values, which causes that the VMs have to wait
for longer time to transmit data. Moreover, distinct from the results in _SLR_ , TDA
obtains the best results in terms of _AVU_. It is because that lots of replicated tasks
processed in TDA can be filled into the idle period of VMs, which benefits the uti-
lization of VMs. Although 9.42% worse than those of TDA, the _AVU_ values of SM-
CPTD are 4.07, 6.56, 12.89% better than those of GSS, NMMWS and min‚Äìmin,
respectively.
It can be found from Figs.¬†9 and 10 that for large-scale workflows, SM-CPTD is
able to obtain the minimum value of _SLR_ regardless of the number of VMs. Moreo-
ver, with the increase in numbers of VMs, the parallel computing capability of VMs
is elevated to decrease the completion time of workflows, while the utilization of
VMs decreases. Furthermore, although approximately 5.26% worse than TDA
in terms of _AVU_ , SM-CPTD obtains 2.98, 6.12 and 11.69% better utilization than
GSS, NMMWS and min‚Äìmin on instance groups with different numbers of VMs,
respectively.
The comparison of _VF_ in different large-scale workflows is shown in Fig.¬†11. The
comparison results show that the proposed algorithm has better _VF_ in all workflows
compared with other algorithms.

**5.2.2 Verification of¬†the¬†proposed methods**

To verify the two local optimization methods presented in this paper, three other
algorithms are also adopted as the comparative algorithms, namely SM, SM-CP and
SM-TD. SM is the original stable matching algorithm without any local optimiza-
tion method. SM-CP is the SM with local optimization method of critical path and
SM-TD is the SM with local optimization method of task duplication. Without loss
of generality, the algorithms are tested on large-scale workflows, we set _m_ to 50
and CCR to 1. The evaluation results are shown in Fig.¬†12. It can be observed from
Fig.¬†12a that both local optimization methods can reduce the makespan of workflow,
and SM-TD is superior to SM-CP. In addition, the performance of the algorithm can
be improved by 11.28% when the two methods are both applied. From Fig.¬†12b, it


11621
A novel cloud workflow scheduling algorithm based on¬†stable...

can be found that since _AVU_ is related to the makespan of workflow, as the makes-
pan decreases, the value of _AVU_ increased as well. Therefore, compared with SM,
SM-CP obtains better results in terms of _AVU_. Moreover, SM-TD utilizes the idle
time of VMs, so that the results of AVU obtained by SM-TD are higher than those
obtained by SM-CP. When the two local optimization methods are both adopted,
SM-CPTD achieves the best utilization with an increase of about 7.69%. It can be
seen from Fig.¬†12c that SM obtains the smallest _VF_ value among all workflows. It
means that the original stable matching algorithm can effectively balance the fair-
ness of each task. However, the fairness of some tasks is affected by the two local
optimization methods. As a result, the value of _VF_ of the other three algorithms is
larger than that of SM.
In conclusion, our proposed algorithm SM-CPTD shows better performance than
all the other algorithms. Moreover, the two local optimization methods, DCP and
LOTD, are able to reduce the makespan of workflow effectively. In addition, when
the value of CCR is set to one, the ranges of the average running time of SM-CPTD
for small-scale, medium-scale and large-scale workflows with four different struc-
tures are 10‚Äì20, 30‚Äì40, 1200‚Äì1400¬†ms, respectively. Therefore, SM-CPTD is highly
efficient and can be applied in online workflow scheduling scenarios.

**6 Conclusions**

Considering the requirement of task fairness in real-world workflow applications,
a novel scheduling algorithm based on stable matching game theory, called SM-
CPTD, is proposed for minimizing the workflow makespan and maximizing the task
fairness. In addition, two local optimization methods based on critical path and task
duplication, respectively, are presented and incorporated into SM-CPTD to reduce
the completion time of critical tasks and take full advantage of the free VMs. The
experimental results in terms of _SLR_ , _AVU_ and _VF_ demonstrated that the proposed
algorithm can effectively reduce the makespan of workflow, obtain better utilization
of VMs and ensure the fairness of the tasks, simultaneously.
In the future, multiple objectives such as cost and energy consumption can be
taken into consideration. Meanwhile, it is of great interest to investigate the work-
flow scheduling in the mobile edge computing environment where computation
tasks are required to be offloaded to either the edge server or the cloud server before
they are processed.

**Acknowledgements** This work is supported by the National Natural Science Foundation under Grants
71971002 and 61872002, the Humanity and Social Science Youth Foundation of Ministry of Education
of China under Grant 15YJC630041 and the Natural Science Foundation of Anhui Provincial Department
of Education under Grant KJ2015A062.

**References**

1. Mukherjee D, Nandy S, Mohan S, Al-Otaibi YD, Alnumay WS (2021) Sustainable task scheduling
    strategy in cloudlets. Sustain Comput: Inform Syst 30:100513


11622 Z.¬†Jia et al.

2. Buyya R, Yeo CS, Venugopal S, Broberg J, Brandic I (2009) Cloud computing and emerging it plat-
    forms: vision, hype, and reality for delivering computing as the 5th utility. Fut Gener Comput Syst
    25(6):599‚Äì616
3. Wu Z, Liu X, Ni Z, Yuan D, Yang Y (2013) A market-oriented hierarchical scheduling strategy in
    cloud workflow systems. J Supercomput 63(1):256‚Äì293
4. Deelman E, Gannon D, Shields M, Taylor I (2009) Workflows and e-science: an overview of work-
    flow system features and capabilities. Fut Gener Comput Syst 25(5):528‚Äì540
5. Liu X, Chen J, Liu K, Yang Y (2008) Forecasting duration intervals of scientific workflow activities
    based on time-series patterns. In: 2008 IEEE 4th International Conference on eScience. IEEE, pp
    23‚Äì30
6. Darbha S, Agrawal DP (1998) Optimal scheduling algorithm for distributed-memory machines.
    IEEE Trans Parallel Distrib Syst 9(1):87‚Äì95
7. Xie Y, Zhu Y, Wang Y, Cheng Y, Xu R, Sani AS, Yuan D, Yang Y (2019) A novel directional and
    non-local-convergent particle swarm optimization based workflow scheduling in cloud-edge envi-
    ronment. Fut Gener Comput Syst 97:361‚Äì378
8. Huang B, Li Z, Tang P, Wang S, Zhao J, Hu H, Li W, Chang V (2019) Security modeling and effi-
    cient computation offloading for service workflow in mobile edge computing. Fut Gener Comput
    Syst 97:755‚Äì774
9. Shih CS, Wei JW, Hung SH, Chen J, Chang N (2013) Fairness scheduler for virtual machines on
    heterogonous multi-core platforms. ACM Sigapp Appl Comput Rev 13(1):28‚Äì40
10. Rezaeian A, Naghibzadeh M, Epema DHJ (2019) Fair multiple-workflow scheduling with different
    quality-of-service goals. J Supercomput 75(2):746‚Äì769
11. Jang J, Jung J, Hong J (2019) K-LZF: an efficient and fair scheduling for edge computing servers.
    Fut Gener Comput Syst 98:44‚Äì53
12. Sethuraman J, Teo CP, Qian L (2006) Many-to-one stable matching: geometry and fairness. Math
    Oper Res 31(3):581‚Äì596
13. Zhang Y, Cui L, Zhang Y (2017) A stable matching based elephant flow scheduling algorithm in
    data center networks. Comput Netw 120:186‚Äì197
14. Topcuoglu H, Hariri S, My Wu (2002) Performance-effective and low-complexity task scheduling
    for heterogeneous computing. IEEE Trans Parallel Distrib Syst 13(3):260‚Äì274
15. Xian-Fu M, Wei-Wei L (2010) A dag scheduling algorithm based on selected duplication of prec-
    edent tasks. J Comput-Aided Des Comput Graph 22(6):1056‚Äì1062
16. Geng X, Xu G, Fu X, Zhang Y (2012) A task scheduling algorithm for multi-core-cluster systems.
    JCP 7(11):2797‚Äì2804
17. Chen W, Xie G, Li R, Bai Y, Fan C, Li K (2017) Efficient task scheduling for budget constrained
    parallel applications on heterogeneous cloud computing systems. Fut Gener Comput Syst 74:1‚Äì11
18. Samadi Y, Zbakh M, Tadonki C (2018) E-heft: enhancement heterogeneous earliest finish time
    algorithm for task scheduling based on load balancing in cloud computing. In: 2018 International
    Conference on High Performance Computing and Simulation (HPCS). IEEE, pp 601‚Äì609
19. Tian-mei zi C, Heng-zhou Y, Zhi-dan H (2018) K-heft: a static task scheduling algorithm in clouds.
    In: Proceedings of the 3rd International Conference on Intelligent Information Processing, pp
    152‚Äì159
20. Sahni J, Vidyarthi DP (2015) A cost-effective deadline-constrained dynamic scheduling algorithm
    for scientific workflows in a cloud environment. IEEE Trans Cloud Comput 6(1):2‚Äì18
21. Zheng W, Qin Y, Bugingo E, Zhang D, Chen J (2018) Cost optimization for deadline-aware sched-
    uling of big-data processing jobs on clouds. Fut Gener Comput Syst 82:244‚Äì255
22. Wu T, Gu H, Zhou J, Wei T, Liu X, Chen M (2018) Soft error-aware energy-efficient task schedul-
    ing for workflow applications in DVFS-enabled cloud. J Syst Arch 84:12‚Äì27
23. Ijaz S, Munir EU (2019) Mopt: list-based heuristic for scheduling workflows in cloud environment.
    J Supercomput 75(7):3740‚Äì3768
24. Zhang H, Zheng X, Xia Y, Li M (2019) Workflow scheduling in the cloud with weighted upward-
    rank priority scheme using random walk and uniform spare budget splitting. IEEE Access
    7:60359‚Äì60375
25. Djigal H, Feng J, Lu J, Ge J (2020) IPPTS: an efficient algorithm for scientific workflow scheduling
    in heterogeneous computing systems. IEEE Trans Parallel Distrib Syst 32(5):1057‚Äì1071
26. Geng X, Mao Y, Xiong M, Liu Y (2019) An improved task scheduling algorithm for scientific
    workflow in cloud computing environment. Clust Comput 22(3):7539‚Äì7548


11623
A novel cloud workflow scheduling algorithm based on¬†stable...

27. Kumar MS, Gupta I, Panda SK, Jana PK (2017) Granularity-based workflow scheduling algorithm
    for cloud computing. J Supercomput 73(12):5440‚Äì5464
28. Gupta I, Kumar MS, Jana PK (2018) Efficient workflow scheduling algorithm for cloud computing
    system: a dynamic priority-based approach. Arab J Sci Eng 43(12):7945‚Äì7960
29. Maheswaran M, Ali S, Siegel HJ, Hensgen D, Freund RF (1999) Dynamic mapping of a class of
    independent tasks onto heterogeneous computing systems. J Parallel Distrib Comput 59(2):107‚Äì131
30. Elsherbiny S, Eldaydamony E, Alrahmawy M, Reyad AE (2018) An extended intelligent water drops
    algorithm for workflow scheduling in cloud computing environment. Egypt Inform J 19(1):33‚Äì55
31. Wu Z, Ni Z, Gu L, Liu X (2010) A revised discrete particle swarm optimization for cloud workflow
    scheduling. In: 2010 International Conference on Computational Intelligence and Security, IEEE,
    pp 184‚Äì188
32. Kaur M, Kadam S (2018) A novel multi-objective bacteria foraging optimization algorithm (MOB-
    FOA) for multi-objective scheduling. Appl Soft Comput 66:183‚Äì195
33. Hu H, Li Z, Hu H, Chen J, Ge J, Li C, Chang V (2018) Multi-objective scheduling for scientific
    workflow in multicloud environment. J Netw Comput Appl 114:108‚Äì122
34. Huang CL, Jiang YZ, Yin Y, Yeh WC, Chung VYY, Lai CM (2018) Multi objective scheduling
    in cloud computing using Mosso. In: 2018 IEEE Congress on Evolutionary Computation (CEC).
    IEEE, pp 1‚Äì8
35. Ding R, Li X, Liu X, Xu J (2018) A cost-effective time-constrained multi-workflow scheduling
    strategy in fog computing. In: International Conference on Service-Oriented Computing. Springer,
    pp 194‚Äì207
36. Alsmady A, Al-Khraishi T, Mardini W, Alazzam H, Khamayseh Y (2019) Workflow scheduling in
    cloud computing using memetic algorithm. In: 2019 IEEE Jordan International Joint Conference on
    Electrical Engineering and Information Technology (JEEIT). IEEE, pp 302‚Äì306
37. Yang J, Jiang B, Lv Z, Choo KKR (2020) A task scheduling algorithm considering game theory
    designed for energy management in cloud computing. Fut Gener Comput Syst 105:985‚Äì992
38. Gao Z, Wang Y, Gao Y, Ren X (2018) Multi-objective non-cooperative game model for cost-based
    task scheduling in computational grid. arXiv preprint arXiv: 1807. 05506
39. Wang Y, Jiang J, Xia Y, Wu Q, Luo X, Zhu Q (2018) A multi-stage dynamic game-theoretic
    approach for multi-workflow scheduling on heterogeneous virtual machines from multiple infra-
    structure-as-a-service clouds. In: International Conference on Services Computing. Springer, pp
    137‚Äì152
40. Sujana JAJ, Revathi T, Karthiga G, Raj RV (2015). Game multi objective scheduling algorithm for
    scientific workflows in cloud computing. In: 2015 International Conference on Circuits, Power and
    Computing Technologies [ICCPCT-2015]. IEEE, pp 1‚Äì6
41. Zhang M, Li H, Liu L, Buyya R (2018) An adaptive multi-objective evolutionary algorithm for con-
    strained workflow scheduling in clouds. Distrib Parallel Databases 36(2):339‚Äì368
42. Chen L, Li X, Ruiz R (2018) Idle block based methods for cloud workflow scheduling with preemp-
    tive and non-preemptive tasks. Fut Gener Comput Syst 89:659‚Äì669
43. Shishido HY, Estrella JC, Toledo CFM, Arantes MS (2018) Genetic-based algorithms applied to a
    workflow scheduling algorithm with security and deadline constraints in clouds. Comput Electr Eng
    69:378‚Äì394
44. Casas I, Taheri J, Ranjan R, Wang L, Zomaya AY (2018) GA-ETI: an enhanced genetic algorithm
    for the scheduling of scientific workflows in cloud environments. J Comput Sci 6:318‚Äì331
45. Saharan S, Somani G, Gupta G, Verma R, Gaur MS, Buyya R (2020) QuickDedup: Efficient VM
    deduplication in cloud computing environments. J Parallel Distrib Comput 139:18‚Äì31
46. Manasrah AM, Ba¬† Ali H (2018) Workflow scheduling using hybrid GA-PSO algorithm in cloud
    computing. Wirel Commun Mob Comput 2018
47. Li W, Xia Y, Zhou M, Sun X, Zhu Q (2018) Fluctuation-aware and predictive workflow scheduling
    in cost-effective infrastructure-as-a-service clouds. IEEE Access 6:61488‚Äì61502
48. Ismayilov G, Topcuoglu HR (2018) Dynamic multi-objective workflow scheduling for cloud com-
    puting based on evolutionary algorithms. In: 2018 IEEE/ACM International Conference on Utility
    and Cloud Computing Companion (UCC companion). IEEE, pp 103‚Äì108
49. Adhikari M, Koley S (2018) Cloud computing: a multi-workflow scheduling algorithm with
    dynamic reusability. Arab J Sci Eng 43(2):645‚Äì660
50. Kumar MS, Gupta I, Jana PK (2017) Delay-based workflow scheduling for cost optimization in
    heterogeneous cloud system. In: 2017 10th International Conference on Contemporary Computing
    (IC3). IEEE, pp 1‚Äì6


11624 Z.¬†Jia et al.

51. Choudhary A, Gupta I, Singh V, Jana PK (2018) A GSA based hybrid algorithm for bi-objective
    workflow scheduling in cloud computing. Fut Gener Comput Syst 83:14‚Äì26
52. Luo F, Yuan Y, Ding W, Lu H (2018) An improved particle swarm optimization algorithm based
    on adaptive weight for task scheduling in cloud computing. In: Proceedings of the 2nd International
    Conference on Computer Science and Application Engineering, pp 1‚Äì5
53. Mohanapriya N, Kousalya G, Balakrishnan P, Pethuru Raj C (2018) Energy efficient workflow
    scheduling with virtual machine consolidation for green cloud computing. J Intell Fuzzy Syst
    34(3):1561‚Äì1572
54. Center SC (2014). Cybershake and epigenomics scientific workflow. https:// confl uence. pegas us. isi.
    edu/ displ ay/ pegas us/ Workfl owGe nerat or

**Publisher‚Äôs Note** Springer Nature remains neutral with regard to jurisdictional claims in published
maps and institutional affiliations.


